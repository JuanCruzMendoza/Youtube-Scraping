{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from all_data import create_df\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:09,  5.45it/s]\n"
     ]
    }
   ],
   "source": [
    "df = create_df('AIzaSyCarGpEfvHg-9zsYEMpbZ754o1OvsuBvok', 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the types (find way to do it in all_data.py)\n",
    "df[\"views\"]=df[\"views\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('mydatabase2.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('all_data', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class YTstats:\n",
    "\n",
    "    def __init__(self, api_key, channel_id):\n",
    "        self.api_key = api_key\n",
    "        self.channel_id = channel_id\n",
    "        self.channel_statistics = None\n",
    "        self.video_data = None\n",
    "\n",
    "    def extract_all(self):\n",
    "        self.get_channel_statistics()\n",
    "        self.get_channel_video_data()\n",
    "\n",
    "    def get_channel_statistics(self):\n",
    "        \"\"\"Extract the channel statistics\"\"\"\n",
    "        print('get channel statistics...')\n",
    "        url = f'https://www.googleapis.com/youtube/v3/channels?part=statistics&id={self.channel_id}&key={self.api_key}'\n",
    "        pbar = tqdm(total=1)\n",
    "        \n",
    "        json_url = requests.get(url)\n",
    "        data = json.loads(json_url.text)\n",
    "        try:\n",
    "            data = data['items'][0]['statistics']\n",
    "        except KeyError:\n",
    "            print('Could not get channel statistics')\n",
    "            data = {}\n",
    "\n",
    "        self.channel_statistics = data\n",
    "        pbar.update()\n",
    "        pbar.close()\n",
    "        return data\n",
    "\n",
    "    def get_channel_video_data(self):\n",
    "        \"Extract all video information of the channel\"\n",
    "        print('get video data...')\n",
    "        channel_videos, channel_playlists = self._get_channel_content(limit=50)\n",
    "\n",
    "        parts=[\"snippet\", \"statistics\",\"contentDetails\", \"topicDetails\"]\n",
    "        for video_id in tqdm(channel_videos):\n",
    "            for part in parts:\n",
    "                data = self._get_single_video_data(video_id, part)\n",
    "                channel_videos[video_id].update(data)\n",
    "\n",
    "        self.video_data = channel_videos\n",
    "        return channel_videos\n",
    "\n",
    "    def _get_single_video_data(self, video_id, part):\n",
    "        \"\"\"\n",
    "        Extract further information for a single video\n",
    "        parts can be: 'snippet', 'statistics', 'contentDetails', 'topicDetails'\n",
    "        \"\"\"\n",
    "\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/videos?part={part}&id={video_id}&key={self.api_key}\"\n",
    "        json_url = requests.get(url)\n",
    "        data = json.loads(json_url.text)\n",
    "        try:\n",
    "            data = data['items'][0][part]\n",
    "        except KeyError as e:\n",
    "            print(f'Error! Could not get {part} part of data: \\n{data}')\n",
    "            data = dict()\n",
    "        return data\n",
    "\n",
    "    def _get_channel_content(self, limit=None, check_all_pages=True):\n",
    "        \"\"\"\n",
    "        Extract all videos and playlists, can check all available search pages\n",
    "        channel_videos = videoId: title, publishedAt\n",
    "        channel_playlists = playlistId: title, publishedAt\n",
    "        return channel_videos, channel_playlists\n",
    "        \"\"\"\n",
    "        url = f\"https://www.googleapis.com/youtube/v3/search?key={self.api_key}&channelId={self.channel_id}&part=snippet,id&order=date\"\n",
    "        if limit is not None and isinstance(limit, int):\n",
    "            url += \"&maxResults=\" + str(limit)\n",
    "\n",
    "        vid, pl, npt = self._get_channel_content_per_page(url)\n",
    "        idx = 0\n",
    "        while(check_all_pages and npt is not None and idx < 10):\n",
    "            nexturl = url + \"&pageToken=\" + npt\n",
    "            next_vid, next_pl, npt = self._get_channel_content_per_page(nexturl)\n",
    "            vid.update(next_vid)\n",
    "            pl.update(next_pl)\n",
    "            idx += 1\n",
    "\n",
    "        return vid, pl\n",
    "\n",
    "    def _get_channel_content_per_page(self, url):\n",
    "        \"\"\"\n",
    "        Extract all videos and playlists per page\n",
    "        return channel_videos, channel_playlists, nextPageToken\n",
    "        \"\"\"\n",
    "        json_url = requests.get(url)\n",
    "        data = json.loads(json_url.text)\n",
    "        channel_videos = dict()\n",
    "        channel_playlists = dict()\n",
    "        if 'items' not in data:\n",
    "            print('Error! Could not get correct channel data!\\n', data)\n",
    "            return channel_videos, channel_videos, None\n",
    "\n",
    "        nextPageToken = data.get(\"nextPageToken\", None)\n",
    "\n",
    "        item_data = data['items']\n",
    "        for item in item_data:\n",
    "            try:\n",
    "                kind = item['id']['kind']\n",
    "                published_at = item['snippet']['publishedAt']\n",
    "                title = item['snippet']['title']\n",
    "                if kind == 'youtube#video':\n",
    "                    video_id = item['id']['videoId']\n",
    "                    channel_videos[video_id] = {'publishedAt': published_at, 'title': title}\n",
    "                elif kind == 'youtube#playlist':\n",
    "                    playlist_id = item['id']['playlistId']\n",
    "                    channel_playlists[playlist_id] = {'publishedAt': published_at, 'title': title}\n",
    "            except KeyError as e:\n",
    "                print('Error! Could not extract data from item:\\n', item)\n",
    "\n",
    "        return channel_videos, channel_playlists, nextPageToken\n",
    "\n",
    "    def dump(self):\n",
    "        \"\"\"Dumps channel statistics and video data in a single json file\"\"\"\n",
    "        if self.channel_statistics is None or self.video_data is None:\n",
    "            print('data is missing!\\nCall get_channel_statistics() and get_channel_video_data() first!')\n",
    "            return\n",
    "\n",
    "        fused_data = {self.channel_id: {\"channel_statistics\": self.channel_statistics,\n",
    "                              \"video_data\": self.video_data}}\n",
    "\n",
    "        channel_title = self.video_data.popitem()[1].get('channelTitle', self.channel_id)\n",
    "        channel_title = channel_title.replace(\" \", \"_\").lower()\n",
    "        filename = channel_title + '.json'\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(fused_data, f, indent=4)\n",
    "        \n",
    "        print('file dumped to', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method YTstats.get_channel_statistics of <__main__.YTstats object at 0x000001F5B3D10A30>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = YTstats('AIzaSyCarGpEfvHg-9zsYEMpbZ754o1OvsuBvok', \"UCGie8GMlUo3kBKIopdvumVQ\")\n",
    "stats = data.get_channel_statistics "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
